{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compatibility with Python 3\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Basic packages\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import astropy.io.fits as pyfits\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Matplotlib adjustments (you might not need all of these)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.cm as cmx\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "matplotlib.rc('text', usetex = True)\n",
    "params = {'text.latex.preamble': [r'\\usepackage{upgreek}', r'\\usepackage{amsmath}'],'font.family' : 'lmodern','font.size' : 11}   \n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# Change Work directory (if Gemini2)\n",
    "try:\n",
    "    localFilePath = '/shared-storage/buder/svn-repos/trunk/GALAH/'\n",
    "    os.chdir(localFilePath)\n",
    "except:\n",
    "    print('Could not change Path to '+localFilePath)\n",
    "\n",
    "########################################\n",
    "# THIS IS THE IMPORTANT PART TO ADJUST #\n",
    "########################################\n",
    "\n",
    "# IRAF REDUCTION VERSION\n",
    "\n",
    "DR                  = 'dr5.2'  # default: 'dr5.2', this code is also compatible with 'dr5.1'\n",
    "backup_DR_date      = '170523' # insert here only the last known date! By default, the code will try to use the latest\n",
    "complete_DR         = True     # default: True, otherwise provide files in 'SPECTRA/FIELD/*.fits'\n",
    "field               = ''       # default: not set, if complete_DR == False, set field name here\n",
    "\n",
    "# ADDITIONAL CORRECTIONS BY WG4\n",
    "\n",
    "telluric_correction = True #True\n",
    "skyline_correction  = True #True\n",
    "renormalise         = False\n",
    "\n",
    "# CANNON WAVELENGTH GRID\n",
    "\n",
    "include_ccd4        = True\n",
    "\n",
    "# Define the 4 CCD grids for the Cannon leaving at least 20 km/s to ab lines\n",
    "x1=np.arange(4715.94,4896.00,0.046) # ab lines 4716.3 - 4892.3\n",
    "x2=np.arange(5650.06,5868.25,0.055) # ab lines 5646.0 - 5867.8 # increased red start\n",
    "x3=np.arange(6480.52,6733.92,0.064) # ab lines 6481.6 - 6733.4\n",
    "x4=np.arange(7693.50,7875.55,0.074) # ab lines 7691.2 - 7838.5 # increased red start\n",
    "\n",
    "########################################\n",
    "#        END OF PART TO ADJUST         #\n",
    "########################################\n",
    "\n",
    "# some initial values:\n",
    "clight = 299792.458 # speed of light in km/s\n",
    "large  = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "#       IMPORT OF SOBJECT IRAF         #\n",
    "########################################\n",
    "\n",
    "# This file was intended for 'dr52' but is also compatible with irafdr51\n",
    "\n",
    "if DR == 'dr5.2':\n",
    "    versions = glob.glob('DATA/sobject_iraf_52_*.fits')\n",
    "else:\n",
    "    versions = ['DATA/iraf_dr51_09232016_corrected.fits']\n",
    "\n",
    "# Read in information from the IRAF FITS\n",
    "door = pyfits.open(versions[-1])\n",
    "iraf = door[1].data\n",
    "door.close()\n",
    "\n",
    "print(versions[-1]+' will be used.')\n",
    "print('Available entries in IRAF FITS:  '+str(len(iraf['sobject_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "#       FIND OBSERVATION DATES         #\n",
    "########################################\n",
    "\n",
    "# First we change the working directory to the DR spectra one\n",
    "try:\n",
    "    localFilePath = '/shared-storage/buder/svn-repos/trunk/GALAH/SPECTRA/'+DR\n",
    "    os.chdir(localFilePath)\n",
    "except:\n",
    "    print('Could not change Path to '+localFilePath)\n",
    "\n",
    "# Find all directories with observations (OBS_DATE: YYMMDD), starting with 1 until 2020 and 2 for 2020-2029\n",
    "obs_dates            = np.concatenate((glob.glob('1*'),glob.glob('2*')))\n",
    "obs_dates.sort()\n",
    "obs_date_file_number_01 = []\n",
    "obs_date_file_number_02 = []\n",
    "for each_obs_date in obs_dates:\n",
    "    # Find number of files in each obs_date directory ending with '1.fits'\n",
    "    obs_date_file_number_01.append(len(glob.glob(each_obs_date+'/standard/com/*1.fits')))\n",
    "for each_obs_date in obs_dates:\n",
    "    # Find number of files in each obs_date directory ending with '1.fits'\n",
    "    obs_date_file_number_02.append(len(glob.glob(each_obs_date+'/standard/com2/*1.fits')))\n",
    "\n",
    "\n",
    "try:\n",
    "    localFilePath = '/shared-storage/buder/svn-repos/trunk/GALAH/'\n",
    "    os.chdir(localFilePath)\n",
    "except:\n",
    "    print('Could not change Path to '+localFilePath)\n",
    "    \n",
    "# Print available directories and number of spectra in them\n",
    "\n",
    "print('Available OBS_DATES:')\n",
    "print(zip(obs_dates,obs_date_file_number_01,obs_date_file_number_02))\n",
    "print('Total:')\n",
    "print(str(len(obs_dates))+' OBS_DATES')\n",
    "print(str(sum(obs_date_file_number_01))+' 01 FITS and '+str(sum(obs_date_file_number_02))+' 01 FITS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "#  CREATE TEST_DATA FOR EACH OBS_DATE  #\n",
    "########################################\n",
    "\n",
    "for each_obs_date in obs_dates:\n",
    "    \n",
    "    # Find all FITS (only take those from CCD1 to avoid duplicates)\n",
    "    \n",
    "    # Name of the PICKLE file\n",
    "    if include_ccd4 == True:\n",
    "        file_in_name = '/shared-storage/buder/svn-repos/trunk/GALAH/CANNON/'+DR+'/pickle_'+DR+'_4ccds/'+DR+'_4ccds_'+each_obs_date+'.pickle'\n",
    "    else:\n",
    "        file_in_name = '/shared-storage/buder/svn-repos/trunk/GALAH/CANNON/'+DR+'/pickle_'+DR+'_3ccds/'+DR+'_3ccds_'+each_obs_date+'.pickle'\n",
    "\n",
    "    if not glob.glob(file_in_name):\n",
    "\n",
    "        print(each_obs_date+' - creating PICKLE')\n",
    "\n",
    "        try:\n",
    "\n",
    "            file_in = open(file_in_name,'w')\n",
    "\n",
    "\n",
    "            localFilePath = '/shared-storage/buder/svn-repos/trunk/GALAH/SPECTRA/'+DR+'/'+each_obs_date+'/standard/com/'\n",
    "            os.chdir(localFilePath)\n",
    "            obs_date_files_01 = glob.glob('*1.fits')\n",
    "            try:\n",
    "                localFilePath = '/shared-storage/buder/svn-repos/trunk/GALAH/SPECTRA/'+DR+'/'+each_obs_date+'/standard/com2/'\n",
    "                os.chdir(localFilePath)\n",
    "                obs_date_files_02 = glob.glob('*1.fits')\n",
    "            except:\n",
    "                obs_date_files_02 = []\n",
    "            localFilePath = '/shared-storage/buder/svn-repos/trunk/GALAH/'\n",
    "            os.chdir(localFilePath)\n",
    "\n",
    "            # Get rid of '1.fits' end to be able to match with SOBJECT_ID\n",
    "            obs_date_fits_01  = np.array(map(lambda each: obs_date_files_01[each][0:15],range(len(obs_date_files_01))))\n",
    "            obs_date_fits_01.sort()\n",
    "            try:\n",
    "                obs_date_fits_02  = np.array(map(lambda each: obs_date_files_02[each][0:15],range(len(obs_date_files_02))))\n",
    "                obs_date_fits_02.sort()\n",
    "            except:\n",
    "                obs_date_fits_02 = []\n",
    "\n",
    "            # Now we have to pull the information for each FITS form the IRAF table\n",
    "\n",
    "            '''\n",
    "            Start the main part of the code here: creating PICKLE files for each OBS_DATE\n",
    "            '''\n",
    "\n",
    "            # For EACH_FITS of OBS_DATE_FITS, collect GALAH_ID and flux\n",
    "\n",
    "            galah_fits    = []\n",
    "            galah_id      = []\n",
    "\n",
    "            cannon_wave   = []\n",
    "            cannon_flux   = []\n",
    "            cannon_eflux  = []\n",
    "\n",
    "            fits_in_iraf    = []\n",
    "\n",
    "            '''\n",
    "            Start the main iteration (EACH_FITS) for each OBS_DATE, i.e. the input for PICKLE\n",
    "            '''\n",
    "\n",
    "            for each_fits in obs_date_fits_01:\n",
    "\n",
    "                # We can of course only use the spectrum, if the 4th extension is available\n",
    "                try:\n",
    "\n",
    "                    # Cross-match FITS name with IRAF SOBJECT_ID\n",
    "                    fits_in_iraf = np.where(int(each_fits) == iraf['sobject_id'])[0]\n",
    "\n",
    "                    # Forced crash if FITS not found\n",
    "                    if not fits_in_iraf:\n",
    "                        sys.exit('The FITS '+each_fits+' is not in IRAF '+DR)\n",
    "                    else:\n",
    "                        fits_in_iraf = fits_in_iraf[0]\n",
    "\n",
    "                    # Pull VRAD and V_BARY from IRAF or other source\n",
    "\n",
    "                    if DR=='dr5.2':\n",
    "                        vrad = iraf['rv_guess_shift'][fits_in_iraf]\n",
    "                        v_bary = iraf['v_bary'][fits_in_iraf]\n",
    "                        #print(iraf['red_flag'][fits_in_iraf])\n",
    "                    if DR == 'dr51':\n",
    "                        vrad = iraf['vrad'][fits_in_iraf]\n",
    "                        combs=len(fits1[0].header['COMB*'])\n",
    "                        bary_fits=pyfits.open('DATA/GALAH_vbary_09232016.fits')\n",
    "                        v_bary=[]\n",
    "                        for baries in range(0,combs):\n",
    "                            bary_pos=np.where(bary_fits[1].data['out_name']==fits1[0].header['COMB'+str(baries)])[0]\n",
    "                            if len(bary_pos)==1:\n",
    "                                    v_bary.append(bary_fits[1].data['v_bary'][bary_pos[0]])\n",
    "                            else:\n",
    "                                    sys.exit('NO V_BARY ENTRY FOUND')\n",
    "                        v_bary=np.mean(v_bary)\n",
    "\n",
    "                    ''' IMPORT CCD1 '''\n",
    "\n",
    "                    if complete_DR == True:\n",
    "                        if DR=='dr5.2':\n",
    "                                fits1 = pyfits.open(\"SPECTRA/dr5.2/\"+each_fits[0:6]+\"/standard/com/\"+each_fits+\"1.fits\")\n",
    "                        if DR=='dr5.1':\n",
    "                                fits1 = pyfits.open(\"SPECTRA/irafdr51/\"+each_fits[0:6]+\"/combined/\"+each_fits+\"1.fits\")\n",
    "                    else:\n",
    "                        fits1 = pyfits.open(\"SPECTRA/\"+field+\"/\"+each_fits+\"1.fits\")\n",
    "\n",
    "                    if telluric_correction == True:\n",
    "                        telluric_fits = pyfits.open('DATA/telluric_noao_21k.fits')\n",
    "                        wave_tel      = telluric_fits[1].data['wave']/(1.0+(vrad-v_bary)/clight)\n",
    "\n",
    "                    if skyline_correction  == True:\n",
    "                        sky_mask=pyfits.open('DATA/Skyspectrum_161105.fits')\n",
    "                        wave_sky=sky_mask[1].data['wave']/(1.0+(vrad-v_bary)/clight)\n",
    "\n",
    "                    ws=fits1[4].header[\"CRVAL1\"]\n",
    "                    inc=fits1[4].header[\"CDELT1\"]\n",
    "                    nax=fits1[4].header[\"NAXIS1\"]\n",
    "                    ref=fits1[4].header[\"CRPIX1\"]\n",
    "                    if ref == 0:\n",
    "                        ref=1\n",
    "                    x1raw=map(lambda x:((x-ref+1)*inc+ws),range(0,nax))\n",
    "\n",
    "                    # save normalized flux to y1 and uncertainties to z1\n",
    "                    if renormalise!=True:\n",
    "                        # EITHER TAKE FITS-EXTENSION 4: NORMALIZED FLUX\n",
    "                        y1raw=fits1[4].data[0:nax]\n",
    "                        z1raw=fits1[4].data[0:nax]*fits1[1].data[0:nax]\n",
    "                        y1=np.interp(x1,x1raw,y1raw)\n",
    "                        z1=np.interp(x1,x1raw,z1raw)\n",
    "                                    #z1=y1/np.sqrt(np.median(fits1[0].data)*fits[0].header[\"RO_GAIN\"])\n",
    "                    else:\n",
    "                        # OR USE FITS-EXTENSION 0: REDUCED FLUX AND RENORMALIZE\n",
    "                        y1raw=fits1[4].data[0:nax]\n",
    "                        z1raw=fits1[4].data[0:nax]*fits1[1].data[0:nax]\n",
    "                        y1=np.interp(x1,x1raw,y1raw)\n",
    "                        z1=np.interp(x1,x1raw,z1raw)\n",
    "                        #fit chebychev 2nd order polynomial to fits-extension 0 with continuum pixels estimated during prior training step\n",
    "                        fit1 = np.polynomial.chebyshev.Chebyshev.fit(x=x1[cont1], y=y1[cont1], w=z1[cont1] , deg=3)\n",
    "                        y1=y1/fit1(x1)\n",
    "                        z1=y1/np.sqrt(np.median(fits1[0].data)*fits1[0].header[\"RO_GAIN\"])\n",
    "\n",
    "                    if telluric_correction == True:\n",
    "                        telluric_interp=np.interp(x1,wave_tel,telluric_fits[1].data['flux'])\n",
    "                        telluric_interp[np.logical_or(np.isnan(telluric_interp),telluric_interp<0.81)]=0.81\n",
    "                        telluric_interp[telluric_interp>0.995]=1.0\n",
    "                        z1 += (1./(telluric_interp*5.-4) - 1.)\n",
    "\n",
    "                    if skyline_correction == True:\n",
    "                        sky_interp=np.interp(x1,wave_sky,sky_mask[1].data['sky'])\n",
    "                        z1 += large*sky_interp\n",
    "\n",
    "                    y1[np.logical_or(x1<=x1raw[0],x1>=x1raw[-1])]=1.\n",
    "                    z1[np.logical_or(x1<=x1raw[0],x1>=x1raw[-1])]=large\n",
    "                    fits1.close()\n",
    "\n",
    "                    ''' IMPORT CCD2 '''\n",
    "                    if complete_DR == True:\n",
    "                        if DR=='dr5.2':\n",
    "                                fits2 = pyfits.open(\"SPECTRA/dr5.2/\"+each_fits[0:6]+\"/standard/com/\"+each_fits+\"2.fits\")\n",
    "                        if DR=='dr5.1':\n",
    "                                fits2 = pyfits.open(\"SPECTRA/irafdr51/\"+each_fits[0:6]+\"/combined/\"+each_fits+\"2.fits\")\n",
    "                    else:\n",
    "                        fits1 = pyfits.open(\"SPECTRA/\"+field+\"/\"+each_fits+\"2.fits\")\n",
    "\n",
    "                    ws=fits2[4].header[\"CRVAL1\"]\n",
    "                    inc=fits2[4].header[\"CDELT1\"]\n",
    "                    nax=fits2[4].header[\"NAXIS1\"]\n",
    "                    ref=fits2[4].header[\"CRPIX1\"]\n",
    "                    if ref == 0:\n",
    "                        ref=1\n",
    "                    x2raw=map(lambda x:((x-ref+1)*inc+ws),range(0,nax))\n",
    "                            # save normalized flux to y2 and uncertainties to z2\n",
    "                    if renormalise!=True:\n",
    "                        # EITHER TAKE FITS-EXTENSION 4: NORMALIZED FLUX\n",
    "                        y2raw=fits2[4].data[0:nax]\n",
    "                        z2raw=fits2[4].data[0:nax]*fits2[1].data[0:nax]\n",
    "                        y2=np.interp(x2,x2raw,y2raw)\n",
    "                        z2=np.interp(x2,x2raw,z2raw)\n",
    "                        #z2=y2/np.sqrt(np.median(fits2[0].data)*fits2[0].header[\"RO_GAIN\"])\n",
    "                    else:\n",
    "                        # OR USE FITS-EXTENSION 4: REDUCED FLUX AND RENORMALIZE\n",
    "                        y2raw=fits2[4].data[0:nax]\n",
    "                        z2raw=fits2[4].data[0:nax]*fits2[1].data[0:nax]\n",
    "                        y2=np.interp(x2,x2raw,y2raw)\n",
    "                        z2=np.interp(x2,x2raw,z2raw)\n",
    "                        #fit chebychev 2nd order polynomial to fits-extension 0 with continuum pixels estimated during prior training step\n",
    "                        fit2 = np.polynomial.chebyshev.Chebyshev.fit(x=x2[cont2], y=y2[cont2], w=z2[cont2] , deg=2) # there could be weights included, but since we assume same S/N for GALAH, this would not be helpful\n",
    "                        y2=y2/fit2(x2)\n",
    "                        z2=y2/np.sqrt(np.median(fits2[0].data)*fits2[0].header[\"RO_GAIN\"])\n",
    "\n",
    "                    if telluric_correction == True:\n",
    "                        telluric_interp=np.interp(x2,wave_tel,telluric_fits[1].data['flux'])\n",
    "                        telluric_interp[np.logical_or(np.isnan(telluric_interp),telluric_interp<0.81)]=0.81\n",
    "                        telluric_interp[telluric_interp>0.995]=1.0\n",
    "                        z2 += (1./(telluric_interp*5.-4)-1.)\n",
    "\n",
    "                    if skyline_correction == True:\n",
    "                        sky_interp=np.interp(x2,wave_sky,sky_mask[1].data['sky'])\n",
    "                        z2 += large*sky_interp\n",
    "\n",
    "                    y2[np.logical_or(x2<=x2raw[0],x2>=x2raw[-1])]=1.\n",
    "                    z2[np.logical_or(x2<=x2raw[0],x2>=x2raw[-1])]=large\n",
    "                    fits2.close()\n",
    "\n",
    "                    ''' IMPORT CCD3 '''\n",
    "                    if complete_DR == True:\n",
    "                        if DR=='dr5.2':\n",
    "                                fits3 = pyfits.open(\"SPECTRA/dr5.2/\"+each_fits[0:6]+\"/standard/com/\"+each_fits+\"3.fits\")\n",
    "                        if DR=='dr5.1':\n",
    "                                fits3 = pyfits.open(\"SPECTRA/irafdr51/\"+each_fits[0:6]+\"/combined/\"+each_fits+\"3.fits\")\n",
    "                    else:\n",
    "                        fits1 = pyfits.open(\"SPECTRA/\"+field+\"/\"+each_fits+\"3.fits\")\n",
    "\n",
    "                    ws=fits3[4].header[\"CRVAL1\"]\n",
    "                    inc=fits3[4].header[\"CDELT1\"]\n",
    "                    nax=fits3[4].header[\"NAXIS1\"] # taken fixed 4096 because of varying nax +-2\n",
    "                    #nax=4096\n",
    "                    ref=fits3[4].header[\"CRPIX1\"]\n",
    "                    if ref == 0:\n",
    "                        ref=1\n",
    "                    x3raw=map(lambda x:((x-ref+1)*inc+ws),range(0,nax))\n",
    "                    # save normalized flux to y3 and uncertainties to z3\n",
    "                    if renormalise!=True:\n",
    "                        # EITHER TAKE FITS-EXTENSION 4: NORMALIZED FLUX\n",
    "                        y3raw=fits3[4].data[0:nax]\n",
    "                        z3raw=fits3[4].data[0:nax]*fits3[1].data[0:nax]\n",
    "                        y3=np.interp(x3,x3raw,y3raw)\n",
    "                        z3=np.interp(x3,x3raw,z3raw)\n",
    "                        #z3=y3/np.sqrt(np.median(fits3[0].data)*fits3[0].header[\"RO_GAIN\"])\n",
    "                    else:\n",
    "                        # OR USE FITS-EXTENSION 4: REDUCED FLUX AND RENORMALIZE\n",
    "                        y3raw=fits3[4].data[0:nax]\n",
    "                        y3=np.interp(x3,x3raw,y3raw)\n",
    "                        #fit chebychev 2nd order polynomial to fits-extension 0 with continuum pixels estimated during prior training step\n",
    "                        fit3 = np.polynomial.chebyshev.Chebyshev.fit(x=x3[pixlist3], y=y3[pixlist3] , deg=2) # there could be weights included, but since we assume same S/N for GALAH, this would not be helpful\n",
    "                        y3=y3/fit3(x3)\n",
    "                        z3=y3/np.sqrt(np.median(fits3[0].data)*fits3[0].header[\"RO_GAIN\"])\n",
    "\n",
    "                    if telluric_correction == True:\n",
    "                        telluric_interp=np.interp(x3,wave_tel,telluric_fits[1].data['flux'])\n",
    "                        telluric_interp[np.logical_or(np.isnan(telluric_interp),telluric_interp<0.81)]=0.81\n",
    "                        telluric_interp[telluric_interp>0.995]=1.0\n",
    "                        z3 += (1./(telluric_interp*5.-4) - 1.)\n",
    "\n",
    "                    if skyline_correction == True:\n",
    "                        sky_interp=np.interp(x3,wave_sky,sky_mask[1].data['sky'])\n",
    "                        z3 += large*sky_interp\n",
    "\n",
    "                    y3[np.logical_or(x3<=x3raw[0],x3>=x3raw[-1])]=1.\n",
    "                    z3[np.logical_or(x3<=x3raw[0],x3>=x3raw[-1])]=large\n",
    "                    fits3.close()\n",
    "\n",
    "                    ''' IMPORT CCD4 '''\n",
    "                    if include_ccd4 == True:\n",
    "                        if complete_DR == True:\n",
    "                            if DR=='dr5.2':\n",
    "                                    fits4 = pyfits.open(\"SPECTRA/dr5.2/\"+each_fits[0:6]+\"/standard/com/\"+each_fits+\"4.fits\")\n",
    "                            if DR=='dr5.1':\n",
    "                                    fits4 = pyfits.open(\"SPECTRA/irafdr51/\"+each_fits[0:6]+\"/combined/\"+each_fits+\"4.fits\")\n",
    "                        else:\n",
    "                            fits1 = pyfits.open(\"SPECTRA/\"+field+\"/\"+each_fits+\"4.fits\")\n",
    "\n",
    "                        ws=fits4[4].header[\"CRVAL1\"]\n",
    "                        inc=fits4[4].header[\"CDELT1\"]\n",
    "                        nax=fits4[4].header[\"NAXIS1\"] # taken fixed 4096 because of varying nax +-2\n",
    "                        naxir=fits4[1].header[\"NAXIS1\"]\n",
    "                        #nax=4096\n",
    "                        ref=fits4[4].header[\"CRPIX1\"]\n",
    "                        if ref == 0:\n",
    "                            ref=1\n",
    "                        # ir_cut is included, because of the low wavelength cut in fits-extension 4 (to get rid of H20 band < 7700)\n",
    "                        #ir_cut=len(fits4[4].data)\n",
    "                        x4raw=map(lambda x:((x-ref+1)*inc+ws),range(0,nax))\n",
    "\n",
    "                        # save normalized flux to y4 and uncertainties to z4\n",
    "                        if renormalise!=True:\n",
    "                            # EITHER TAKE FITS-EXTENSION 4: NORMALIZED FLUX\n",
    "                            y4raw=fits4[4].data[0:nax]\n",
    "                            z4raw=fits4[4].data[0:nax]*fits4[1].data[naxir-nax:naxir]\n",
    "                            y4=np.interp(x4,x4raw,y4raw)\n",
    "                            z4=np.interp(x4,x4raw,z4raw)\n",
    "                            #z4=y4/np.sqrt(np.median(fits4[0].data)*fits4[0].header[\"RO_GAIN\"])\n",
    "                        else:\n",
    "                            # OR USE FITS-EXTENSION 4: REDUCED FLUX AND RENORMALIZE\n",
    "                            y4raw=fits4[4].data[nax-ir_cut:nax]\n",
    "                            y4s=np.interp(x4,x4raw,y4raw)\n",
    "                            #fit chebychev 2nd order polynomial to fits-extension 0 with continuum pixels estimated during prior training step\n",
    "                            fit4 = np.polynomial.chebyshev.Chebyshev.fit(x=x4[pixlist4], y=y4s[pixlist4] , deg=4) # there could be weights included, but since we assume same S/N for GALAH, this would not be helpful\n",
    "                            y4=y4s/fit4(x4)\n",
    "                            z4=y4/np.sqrt(np.median(fits4[0].data)*fits4[0].header[\"RO_GAIN\"])\n",
    "\n",
    "                        if telluric_correction == True:\n",
    "                            telluric_interp=np.interp(x4,wave_tel,telluric_fits[1].data['flux'])\n",
    "                            telluric_interp[np.logical_or(np.isnan(telluric_interp),telluric_interp<0.81)]=0.81\n",
    "                            telluric_interp[telluric_interp>0.995]=1.0\n",
    "                            z4 += (1./(telluric_interp*5.-4) -1.)\n",
    "\n",
    "                        if skyline_correction == True:\n",
    "                            sky_interp=np.interp(x4,wave_sky,sky_mask[1].data['sky'])\n",
    "                            z4 += large*sky_interp\n",
    "\n",
    "                        y4[np.logical_or(x4<=x4raw[0],x4>=x4raw[-1])]=1.\n",
    "                        z4[np.logical_or(x4<=x4raw[0],x4>=x4raw[-1])]=large\n",
    "                        fits4.close()\n",
    "\n",
    "                    ''' COMBINE CCDs '''\n",
    "                    if include_ccd4==True:\n",
    "                        x = np.concatenate((x1,x2,x3,x4))\n",
    "                        y = np.concatenate((y1,y2,y3,y4))\n",
    "                        z = np.concatenate((z1,z2,z3,z4))\n",
    "\n",
    "                        #print(x2raw[0],x4raw[0])\n",
    "\n",
    "        #                 f,(ax1,ax2,ax3,ax4) = plt.subplots(4)    \n",
    "        #                 ax1.fill_between(x1,y1-z1,y1+z1,alpha=0.5,facecolor='k',lw=0)\n",
    "        #                 ax1.plot(x1,y1,'k',lw=1)\n",
    "        #                 ax2.fill_between(x2,y2-z2,y2+z2,alpha=0.5,facecolor='k',lw=0)\n",
    "        #                 ax2.plot(x2,y2,'k',lw=1)\n",
    "        #                 ax3.fill_between(x3,y3-z3,y3+z3,alpha=0.5,facecolor='k',lw=0)\n",
    "        #                 ax3.plot(x3,y3,'k',lw=1)\n",
    "        #                 ax4.fill_between(x4,y4-z4,y4+z4,alpha=0.5,facecolor='k',lw=0)\n",
    "        #                 ax4.plot(x4,y4,'k',lw=1)\n",
    "        #                 ax1.set_ylim(0.05,1.55)\n",
    "        #                 ax2.set_ylim(0.05,1.55)\n",
    "        #                 ax3.set_ylim(0.05,1.55)\n",
    "        #                 ax4.set_ylim(0.05,1.55)\n",
    "        #                 #ax4.set_xlim(7820,7830)\n",
    "        #                 plt.tight_layout()\n",
    "\n",
    "                    else:\n",
    "                        x = np.concatenate((x1,x2,x3))\n",
    "                        y = np.concatenate((y1,y2,y3))\n",
    "                        z = np.concatenate((z1,z2,z3))\n",
    "\n",
    "                    bady = np.isnan(y)\n",
    "                    badz = np.isnan(z)\n",
    "                    y[bady] = 1.\n",
    "                    z[badz] = large\n",
    "                    bady = np.logical_or(y > 1.5,y <0.0)\n",
    "                    y[bady] = 1.\n",
    "                    z[bady] = large\n",
    "\n",
    "                    galah_fits.append(each_fits)\n",
    "                    galah_id.append(iraf['galah_id'][fits_in_iraf])\n",
    "                    cannon_wave.append(x)\n",
    "                    cannon_flux.append(y)\n",
    "                    cannon_eflux.append(z)\n",
    "\n",
    "                except:\n",
    "                    print('   '+each_fits+' does not have a 4th extension, flag_guess = '+str(iraf['flag_guess'][fits_in_iraf]))\n",
    "\n",
    "            print('   reading in - done 01')\n",
    "\n",
    "            if len(obs_date_fits_02) > 0:\n",
    "                for each_fits in obs_date_fits_02:\n",
    "\n",
    "                    # We can of course only use the spectrum, if the 4th extension is available\n",
    "                    try:\n",
    "\n",
    "                        # Cross-match FITS name with IRAF SOBJECT_ID\n",
    "                        fits_in_iraf = np.where(int(each_fits) == iraf['sobject_id'])[0]\n",
    "\n",
    "                        # Forced crash if FITS not found\n",
    "                        if not fits_in_iraf:\n",
    "                            sys.exit('The FITS '+each_fits+' is not in IRAF '+DR)\n",
    "                        else:\n",
    "                            fits_in_iraf = fits_in_iraf[0]\n",
    "\n",
    "                        # Pull VRAD and V_BARY from IRAF or other source\n",
    "\n",
    "                        if DR=='dr5.2':\n",
    "                            vrad = iraf['rv_guess_shift'][fits_in_iraf]\n",
    "                            v_bary = iraf['v_bary'][fits_in_iraf]\n",
    "                            #print(iraf['red_flag'][fits_in_iraf])\n",
    "                        if DR == 'dr51':\n",
    "                            vrad = iraf['vrad'][fits_in_iraf]\n",
    "                            combs=len(fits1[0].header['COMB*'])\n",
    "                            bary_fits=pyfits.open('DATA/GALAH_vbary_09232016.fits')\n",
    "                            v_bary=[]\n",
    "                            for baries in range(0,combs):\n",
    "                                bary_pos=np.where(bary_fits[1].data['out_name']==fits1[0].header['COMB'+str(baries)])[0]\n",
    "                                if len(bary_pos)==1:\n",
    "                                        v_bary.append(bary_fits[1].data['v_bary'][bary_pos[0]])\n",
    "                                else:\n",
    "                                        sys.exit('NO V_BARY ENTRY FOUND')\n",
    "                            v_bary=np.mean(v_bary)\n",
    "\n",
    "                        ''' IMPORT CCD1 '''\n",
    "\n",
    "                        if complete_DR == True:\n",
    "                            if DR=='dr5.2':\n",
    "                                    fits1 = pyfits.open(\"SPECTRA/dr5.2/\"+each_fits[0:6]+\"/standard/com2/\"+each_fits+\"1.fits\")\n",
    "                            if DR=='dr5.1':\n",
    "                                    fits1 = pyfits.open(\"SPECTRA/irafdr51/\"+each_fits[0:6]+\"/combined/\"+each_fits+\"1.fits\")\n",
    "                        else:\n",
    "                            fits1 = pyfits.open(\"SPECTRA/\"+field+\"/\"+each_fits+\"1.fits\")\n",
    "\n",
    "                        if telluric_correction == True:\n",
    "                            telluric_fits = pyfits.open('DATA/telluric_noao_21k.fits')\n",
    "                            wave_tel      = telluric_fits[1].data['wave']/(1.0+(vrad-v_bary)/clight)\n",
    "\n",
    "                        if skyline_correction  == True:\n",
    "                            sky_mask=pyfits.open('DATA/Skyspectrum_161105.fits')\n",
    "                            wave_sky=sky_mask[1].data['wave']/(1.0+(vrad-v_bary)/clight)\n",
    "\n",
    "                        ws=fits1[4].header[\"CRVAL1\"]\n",
    "                        inc=fits1[4].header[\"CDELT1\"]\n",
    "                        nax=fits1[4].header[\"NAXIS1\"]\n",
    "                        ref=fits1[4].header[\"CRPIX1\"]\n",
    "                        if ref == 0:\n",
    "                            ref=1\n",
    "                        x1raw=map(lambda x:((x-ref+1)*inc+ws),range(0,nax))\n",
    "\n",
    "                        # save normalized flux to y1 and uncertainties to z1\n",
    "                        if renormalise!=True:\n",
    "                            # EITHER TAKE FITS-EXTENSION 4: NORMALIZED FLUX\n",
    "                            y1raw=fits1[4].data[0:nax]\n",
    "                            z1raw=fits1[4].data[0:nax]*fits1[1].data[0:nax]\n",
    "                            y1=np.interp(x1,x1raw,y1raw)\n",
    "                            z1=np.interp(x1,x1raw,z1raw)\n",
    "                                        #z1=y1/np.sqrt(np.median(fits1[0].data)*fits[0].header[\"RO_GAIN\"])\n",
    "                        else:\n",
    "                            # OR USE FITS-EXTENSION 0: REDUCED FLUX AND RENORMALIZE\n",
    "                            y1raw=fits1[4].data[0:nax]\n",
    "                            z1raw=fits1[4].data[0:nax]*fits1[1].data[0:nax]\n",
    "                            y1=np.interp(x1,x1raw,y1raw)\n",
    "                            z1=np.interp(x1,x1raw,z1raw)\n",
    "                            #fit chebychev 2nd order polynomial to fits-extension 0 with continuum pixels estimated during prior training step\n",
    "                            fit1 = np.polynomial.chebyshev.Chebyshev.fit(x=x1[cont1], y=y1[cont1], w=z1[cont1] , deg=3)\n",
    "                            y1=y1/fit1(x1)\n",
    "                            z1=y1/np.sqrt(np.median(fits1[0].data)*fits1[0].header[\"RO_GAIN\"])\n",
    "\n",
    "                        if telluric_correction == True:\n",
    "                            telluric_interp=np.interp(x1,wave_tel,telluric_fits[1].data['flux'])\n",
    "                            telluric_interp[np.logical_or(np.isnan(telluric_interp),telluric_interp<0.81)]=0.81\n",
    "                            telluric_interp[telluric_interp>0.995]=1.0\n",
    "                            z1 += (1./(telluric_interp*5.-4) - 1.)\n",
    "\n",
    "                        if skyline_correction == True:\n",
    "                            sky_interp=np.interp(x1,wave_sky,sky_mask[1].data['sky'])\n",
    "                            z1 += large*sky_interp\n",
    "\n",
    "                        y1[np.logical_or(x1<=x1raw[0],x1>=x1raw[-1])]=1.\n",
    "                        z1[np.logical_or(x1<=x1raw[0],x1>=x1raw[-1])]=large\n",
    "                        fits1.close()\n",
    "\n",
    "                        ''' IMPORT CCD2 '''\n",
    "                        if complete_DR == True:\n",
    "                            if DR=='dr5.2':\n",
    "                                    fits2 = pyfits.open(\"SPECTRA/dr5.2/\"+each_fits[0:6]+\"/standard/com2/\"+each_fits+\"2.fits\")\n",
    "                            if DR=='dr5.1':\n",
    "                                    fits2 = pyfits.open(\"SPECTRA/irafdr51/\"+each_fits[0:6]+\"/combined/\"+each_fits+\"2.fits\")\n",
    "                        else:\n",
    "                            fits1 = pyfits.open(\"SPECTRA/\"+field+\"/\"+each_fits+\"2.fits\")\n",
    "\n",
    "                        ws=fits2[4].header[\"CRVAL1\"]\n",
    "                        inc=fits2[4].header[\"CDELT1\"]\n",
    "                        nax=fits2[4].header[\"NAXIS1\"]\n",
    "                        ref=fits2[4].header[\"CRPIX1\"]\n",
    "                        if ref == 0:\n",
    "                            ref=1\n",
    "                        x2raw=map(lambda x:((x-ref+1)*inc+ws),range(0,nax))\n",
    "                                # save normalized flux to y2 and uncertainties to z2\n",
    "                        if renormalise!=True:\n",
    "                            # EITHER TAKE FITS-EXTENSION 4: NORMALIZED FLUX\n",
    "                            y2raw=fits2[4].data[0:nax]\n",
    "                            z2raw=fits2[4].data[0:nax]*fits2[1].data[0:nax]\n",
    "                            y2=np.interp(x2,x2raw,y2raw)\n",
    "                            z2=np.interp(x2,x2raw,z2raw)\n",
    "                            #z2=y2/np.sqrt(np.median(fits2[0].data)*fits2[0].header[\"RO_GAIN\"])\n",
    "                        else:\n",
    "                            # OR USE FITS-EXTENSION 4: REDUCED FLUX AND RENORMALIZE\n",
    "                            y2raw=fits2[4].data[0:nax]\n",
    "                            z2raw=fits2[4].data[0:nax]*fits2[1].data[0:nax]\n",
    "                            y2=np.interp(x2,x2raw,y2raw)\n",
    "                            z2=np.interp(x2,x2raw,z2raw)\n",
    "                            #fit chebychev 2nd order polynomial to fits-extension 0 with continuum pixels estimated during prior training step\n",
    "                            fit2 = np.polynomial.chebyshev.Chebyshev.fit(x=x2[cont2], y=y2[cont2], w=z2[cont2] , deg=2) # there could be weights included, but since we assume same S/N for GALAH, this would not be helpful\n",
    "                            y2=y2/fit2(x2)\n",
    "                            z2=y2/np.sqrt(np.median(fits2[0].data)*fits2[0].header[\"RO_GAIN\"])\n",
    "\n",
    "                        if telluric_correction == True:\n",
    "                            telluric_interp=np.interp(x2,wave_tel,telluric_fits[1].data['flux'])\n",
    "                            telluric_interp[np.logical_or(np.isnan(telluric_interp),telluric_interp<0.81)]=0.81\n",
    "                            telluric_interp[telluric_interp>0.995]=1.0\n",
    "                            z2 += (1./(telluric_interp*5.-4)-1.)\n",
    "\n",
    "                        if skyline_correction == True:\n",
    "                            sky_interp=np.interp(x2,wave_sky,sky_mask[1].data['sky'])\n",
    "                            z2 += large*sky_interp\n",
    "\n",
    "                        y2[np.logical_or(x2<=x2raw[0],x2>=x2raw[-1])]=1.\n",
    "                        z2[np.logical_or(x2<=x2raw[0],x2>=x2raw[-1])]=large\n",
    "                        fits2.close()\n",
    "\n",
    "                        ''' IMPORT CCD3 '''\n",
    "                        if complete_DR == True:\n",
    "                            if DR=='dr5.2':\n",
    "                                    fits3 = pyfits.open(\"SPECTRA/dr5.2/\"+each_fits[0:6]+\"/standard/com2/\"+each_fits+\"3.fits\")\n",
    "                            if DR=='dr5.1':\n",
    "                                    fits3 = pyfits.open(\"SPECTRA/irafdr51/\"+each_fits[0:6]+\"/combined/\"+each_fits+\"3.fits\")\n",
    "                        else:\n",
    "                            fits1 = pyfits.open(\"SPECTRA/\"+field+\"/\"+each_fits+\"3.fits\")\n",
    "\n",
    "                        ws=fits3[4].header[\"CRVAL1\"]\n",
    "                        inc=fits3[4].header[\"CDELT1\"]\n",
    "                        nax=fits3[4].header[\"NAXIS1\"] # taken fixed 4096 because of varying nax +-2\n",
    "                        #nax=4096\n",
    "                        ref=fits3[4].header[\"CRPIX1\"]\n",
    "                        if ref == 0:\n",
    "                            ref=1\n",
    "                        x3raw=map(lambda x:((x-ref+1)*inc+ws),range(0,nax))\n",
    "                        # save normalized flux to y3 and uncertainties to z3\n",
    "                        if renormalise!=True:\n",
    "                            # EITHER TAKE FITS-EXTENSION 4: NORMALIZED FLUX\n",
    "                            y3raw=fits3[4].data[0:nax]\n",
    "                            z3raw=fits3[4].data[0:nax]*fits3[1].data[0:nax]\n",
    "                            y3=np.interp(x3,x3raw,y3raw)\n",
    "                            z3=np.interp(x3,x3raw,z3raw)\n",
    "                            #z3=y3/np.sqrt(np.median(fits3[0].data)*fits3[0].header[\"RO_GAIN\"])\n",
    "                        else:\n",
    "                            # OR USE FITS-EXTENSION 4: REDUCED FLUX AND RENORMALIZE\n",
    "                            y3raw=fits3[4].data[0:nax]\n",
    "                            y3=np.interp(x3,x3raw,y3raw)\n",
    "                            #fit chebychev 2nd order polynomial to fits-extension 0 with continuum pixels estimated during prior training step\n",
    "                            fit3 = np.polynomial.chebyshev.Chebyshev.fit(x=x3[pixlist3], y=y3[pixlist3] , deg=2) # there could be weights included, but since we assume same S/N for GALAH, this would not be helpful\n",
    "                            y3=y3/fit3(x3)\n",
    "                            z3=y3/np.sqrt(np.median(fits3[0].data)*fits3[0].header[\"RO_GAIN\"])\n",
    "\n",
    "                        if telluric_correction == True:\n",
    "                            telluric_interp=np.interp(x3,wave_tel,telluric_fits[1].data['flux'])\n",
    "                            telluric_interp[np.logical_or(np.isnan(telluric_interp),telluric_interp<0.81)]=0.81\n",
    "                            telluric_interp[telluric_interp>0.995]=1.0\n",
    "                            z3 += (1./(telluric_interp*5.-4) - 1.)\n",
    "\n",
    "                        if skyline_correction == True:\n",
    "                            sky_interp=np.interp(x3,wave_sky,sky_mask[1].data['sky'])\n",
    "                            z3 += large*sky_interp\n",
    "\n",
    "                        y3[np.logical_or(x3<=x3raw[0],x3>=x3raw[-1])]=1.\n",
    "                        z3[np.logical_or(x3<=x3raw[0],x3>=x3raw[-1])]=large\n",
    "                        fits3.close()\n",
    "\n",
    "                        ''' IMPORT CCD4 '''\n",
    "                        if include_ccd4 == True:\n",
    "                            if complete_DR == True:\n",
    "                                if DR=='dr5.2':\n",
    "                                        fits4 = pyfits.open(\"SPECTRA/dr5.2/\"+each_fits[0:6]+\"/standard/com2/\"+each_fits+\"4.fits\")\n",
    "                                if DR=='dr5.1':\n",
    "                                        fits4 = pyfits.open(\"SPECTRA/irafdr51/\"+each_fits[0:6]+\"/combined/\"+each_fits+\"4.fits\")\n",
    "                            else:\n",
    "                                fits1 = pyfits.open(\"SPECTRA/\"+field+\"/\"+each_fits+\"4.fits\")\n",
    "\n",
    "                            ws=fits4[4].header[\"CRVAL1\"]\n",
    "                            inc=fits4[4].header[\"CDELT1\"]\n",
    "                            nax=fits4[4].header[\"NAXIS1\"] # taken fixed 4096 because of varying nax +-2\n",
    "                            naxir=fits4[1].header[\"NAXIS1\"]\n",
    "                            #nax=4096\n",
    "                            ref=fits4[4].header[\"CRPIX1\"]\n",
    "                            if ref == 0:\n",
    "                                ref=1\n",
    "                            # ir_cut is included, because of the low wavelength cut in fits-extension 4 (to get rid of H20 band < 7700)\n",
    "                            #ir_cut=len(fits4[4].data)\n",
    "                            x4raw=map(lambda x:((x-ref+1)*inc+ws),range(0,nax))\n",
    "\n",
    "                            # save normalized flux to y4 and uncertainties to z4\n",
    "                            if renormalise!=True:\n",
    "                                # EITHER TAKE FITS-EXTENSION 4: NORMALIZED FLUX\n",
    "                                y4raw=fits4[4].data[0:nax]\n",
    "                                z4raw=fits4[4].data[0:nax]*fits4[1].data[naxir-nax:naxir]\n",
    "                                y4=np.interp(x4,x4raw,y4raw)\n",
    "                                z4=np.interp(x4,x4raw,z4raw)\n",
    "                                #z4=y4/np.sqrt(np.median(fits4[0].data)*fits4[0].header[\"RO_GAIN\"])\n",
    "                            else:\n",
    "                                # OR USE FITS-EXTENSION 4: REDUCED FLUX AND RENORMALIZE\n",
    "                                y4raw=fits4[4].data[nax-ir_cut:nax]\n",
    "                                y4s=np.interp(x4,x4raw,y4raw)\n",
    "                                #fit chebychev 2nd order polynomial to fits-extension 0 with continuum pixels estimated during prior training step\n",
    "                                fit4 = np.polynomial.chebyshev.Chebyshev.fit(x=x4[pixlist4], y=y4s[pixlist4] , deg=4) # there could be weights included, but since we assume same S/N for GALAH, this would not be helpful\n",
    "                                y4=y4s/fit4(x4)\n",
    "                                z4=y4/np.sqrt(np.median(fits4[0].data)*fits4[0].header[\"RO_GAIN\"])\n",
    "\n",
    "                            if telluric_correction == True:\n",
    "                                telluric_interp=np.interp(x4,wave_tel,telluric_fits[1].data['flux'])\n",
    "                                telluric_interp[np.logical_or(np.isnan(telluric_interp),telluric_interp<0.81)]=0.81\n",
    "                                telluric_interp[telluric_interp>0.995]=1.0\n",
    "                                z4 += (1./(telluric_interp*5.-4) -1.)\n",
    "\n",
    "                            if skyline_correction == True:\n",
    "                                sky_interp=np.interp(x4,wave_sky,sky_mask[1].data['sky'])\n",
    "                                z4 += large*sky_interp\n",
    "\n",
    "                            y4[np.logical_or(x4<=x4raw[0],x4>=x4raw[-1])]=1.\n",
    "                            z4[np.logical_or(x4<=x4raw[0],x4>=x4raw[-1])]=large\n",
    "                            fits4.close()\n",
    "\n",
    "                        ''' COMBINE CCDs '''\n",
    "                        if include_ccd4==True:\n",
    "                            x = np.concatenate((x1,x2,x3,x4))\n",
    "                            y = np.concatenate((y1,y2,y3,y4))\n",
    "                            z = np.concatenate((z1,z2,z3,z4))\n",
    "\n",
    "                            #print(x2raw[0],x4raw[0])\n",
    "\n",
    "            #                 f,(ax1,ax2,ax3,ax4) = plt.subplots(4)    \n",
    "            #                 ax1.fill_between(x1,y1-z1,y1+z1,alpha=0.5,facecolor='k',lw=0)\n",
    "            #                 ax1.plot(x1,y1,'k',lw=1)\n",
    "            #                 ax2.fill_between(x2,y2-z2,y2+z2,alpha=0.5,facecolor='k',lw=0)\n",
    "            #                 ax2.plot(x2,y2,'k',lw=1)\n",
    "            #                 ax3.fill_between(x3,y3-z3,y3+z3,alpha=0.5,facecolor='k',lw=0)\n",
    "            #                 ax3.plot(x3,y3,'k',lw=1)\n",
    "            #                 ax4.fill_between(x4,y4-z4,y4+z4,alpha=0.5,facecolor='k',lw=0)\n",
    "            #                 ax4.plot(x4,y4,'k',lw=1)\n",
    "            #                 ax1.set_ylim(0.05,1.55)\n",
    "            #                 ax2.set_ylim(0.05,1.55)\n",
    "            #                 ax3.set_ylim(0.05,1.55)\n",
    "            #                 ax4.set_ylim(0.05,1.55)\n",
    "            #                 #ax4.set_xlim(7820,7830)\n",
    "            #                 plt.tight_layout()\n",
    "\n",
    "                        else:\n",
    "                            x = np.concatenate((x1,x2,x3))\n",
    "                            y = np.concatenate((y1,y2,y3))\n",
    "                            z = np.concatenate((z1,z2,z3))\n",
    "\n",
    "                        bady = np.isnan(y)\n",
    "                        badz = np.isnan(z)\n",
    "                        y[bady] = 1.\n",
    "                        z[badz] = large\n",
    "                        bady = np.logical_or(y > 1.5,y <0.0)\n",
    "                        y[bady] = 1.\n",
    "                        z[bady] = large\n",
    "\n",
    "                        galah_fits.append(each_fits)\n",
    "                        galah_id.append(iraf['galah_id'][fits_in_iraf])\n",
    "                        cannon_wave.append(x)\n",
    "                        cannon_flux.append(y)\n",
    "                        cannon_eflux.append(z)\n",
    "\n",
    "                    except:\n",
    "                        print('   '+each_fits+' does not have a 4th extension, flag_guess = '+str(iraf['flag_guess'][fits_in_iraf]))\n",
    "\n",
    "                print('   reading in - done 02')\n",
    "\n",
    "\n",
    "            # this combines the data into a single array of these vectors\n",
    "            galah_fits    = np.array(galah_fits)\n",
    "            galah_id      = np.array(galah_id)\n",
    "            cannon_wave   = np.array(cannon_wave)\n",
    "            cannon_flux   = np.array(cannon_flux)\n",
    "            cannon_eflux  = np.array(cannon_eflux)\n",
    "\n",
    "            npix          = np.shape(cannon_wave[0])[0]\n",
    "\n",
    "            dataall       = np.zeros((npix, len(galah_fits), 3))\n",
    "            countit       = np.arange(0,len(cannon_flux),1)\n",
    "\n",
    "            # populate the dataall array with the wavelength, flux and error\n",
    "            for a,b,c,jj in zip(cannon_wave,cannon_flux,cannon_eflux, countit):\n",
    "                dataall[:,jj,0] = a\n",
    "                dataall[:,jj,1] = b\n",
    "                dataall[:,jj,2] = c\n",
    "\n",
    "            nstars = np.shape(dataall)[1]\n",
    "\n",
    "            #  check for bad pixels and set these to 1 and their uncertainties to the value \"large\"\n",
    "            for jj in range(nstars):\n",
    "                bad = np.logical_or(dataall[:,jj,1] < 0.1, dataall[:,jj,1] > 1.5)\n",
    "                dataall[bad,jj,1] = 1.\n",
    "                dataall[bad,jj,2]  = large\n",
    "\n",
    "            meds = np.median(dataall[:,:,1], axis =0)\n",
    "            meds = np.array(meds)\n",
    "            take1 = np.logical_and(meds > 0.8, meds < 1.1) # Upper limit was 1.1 before!\n",
    "\n",
    "            print('   Pickle-shapes: ', np.shape(dataall[:,take1,:]),np.shape(galah_fits),np.shape(galah_id))\n",
    "            pickle.dump((dataall[:,take1,:],galah_fits,galah_id),file_in)\n",
    "            file_in.close()\n",
    "\n",
    "            print('   Saving - done')\n",
    "\n",
    "        except:\n",
    "            print('Could not change Path to '+localFilePath)\n",
    "    else:\n",
    "        print('Does already exist - Skip')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "\n",
    "sender = 'buder@mpia.de'\n",
    "receivers = ['buder@mpia.de']\n",
    "\n",
    "message = \"\"\"From: Gemini2\n",
    "To: buder@mpia.de\n",
    "Subject: \"\"\"+'Creating TEST data '+DR+\"\"\" run finished\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    smtpObj = smtplib.SMTP('localhost')\n",
    "    smtpObj.sendmail(sender, receivers, message)         \n",
    "    print(\"Successfully sent email\")\n",
    "except SMTPException:\n",
    "    print(\"Error: unable to send email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert IPYNB to PY\n",
    "\n",
    "os.chdir('/shared-storage/buder/svn-repos/trunk/GALAH/TheGALAHCannon/')\n",
    "\n",
    "convert_command = 'ipython nbconvert --to script Cannon_maketest.ipynb'\n",
    "os.system(convert_command)\n",
    "\n",
    "os.chdir('/shared-storage/buder/svn-repos/trunk/GALAH/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
